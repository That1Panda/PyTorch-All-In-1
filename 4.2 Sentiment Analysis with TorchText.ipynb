{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Sentiment Analysis with TorchText",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "pip install  -q torch==2.1.0 torchtext==0.16.0 portalocker>=2.0.0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:35:56.503035Z",
     "iopub.execute_input": "2024-11-01T18:35:56.503941Z",
     "iopub.status.idle": "2024-11-01T18:38:08.758966Z",
     "shell.execute_reply.started": "2024-11-01T18:35:56.503893Z",
     "shell.execute_reply": "2024-11-01T18:38:08.757873Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Note: you may need to restart the kernel to use updated packages.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "import random\nimport torch\nfrom torchtext.datasets import IMDB\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.utils.data import DataLoader, random_split\nfrom torchtext.vocab import build_vocab_from_iterator, GloVe\nfrom collections import Counter\n\nSEED = 1234\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\nrandom.seed(SEED)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:38:08.761297Z",
     "iopub.execute_input": "2024-11-01T18:38:08.762168Z",
     "iopub.status.idle": "2024-11-01T18:38:12.046776Z",
     "shell.execute_reply.started": "2024-11-01T18:38:08.762116Z",
     "shell.execute_reply": "2024-11-01T18:38:12.045860Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = zip(*[x[i:] for i in range(2)])\n",
    "    for n_gram in n_grams:\n",
    "        x.append(\" \".join(n_gram))\n",
    "    return x\n",
    "\n",
    "\n",
    "train_iter, test_iter = IMDB(split=(\"train\", \"test\"))\n",
    "train_data = list(train_iter)\n",
    "test_data = list(test_iter)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:38:12.047923Z",
     "iopub.execute_input": "2024-11-01T18:38:12.048334Z",
     "iopub.status.idle": "2024-11-01T18:38:49.138266Z",
     "shell.execute_reply.started": "2024-11-01T18:38:12.048301Z",
     "shell.execute_reply": "2024-11-01T18:38:49.137196Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_train = int(len(train_data) * 0.7)\n",
    "train_data, valid_data = random_split(\n",
    "    train_data, [num_train, len(train_data) - num_train]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Valid: {len(valid_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "tokenizer = get_tokenizer(\"spacy\")\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield generate_bigrams(tokenizer(text))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:38:49.140545Z",
     "iopub.execute_input": "2024-11-01T18:38:49.140884Z",
     "iopub.status.idle": "2024-11-01T18:38:52.815509Z",
     "shell.execute_reply.started": "2024-11-01T18:38:49.140850Z",
     "shell.execute_reply": "2024-11-01T18:38:52.814520Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Train: 17500, Valid: 7500, Test: 25000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n  warnings.warn(\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "UNK_TOKEN = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_data), max_tokens=25000, specials=[UNK_TOKEN, PAD_TOKEN]\n",
    ")\n",
    "vocab.set_default_index(vocab[UNK_TOKEN])  # Set default index for unknown tokens\n",
    "\n",
    "glove_vectors = GloVe(name=\"6B\", dim=100)\n",
    "# vocab.load_vectors(glove_vectors)\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in generate_bigrams(tokenizer(x))]\n",
    "label_pipeline = lambda x: 1 if x == \"pos\" else 0"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:38:52.816651Z",
     "iopub.execute_input": "2024-11-01T18:38:52.817168Z",
     "iopub.status.idle": "2024-11-01T18:42:48.810364Z",
     "shell.execute_reply.started": "2024-11-01T18:38:52.817132Z",
     "shell.execute_reply": "2024-11-01T18:42:48.809577Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": ".vector_cache/glove.6B.zip: 862MB [02:41, 5.34MB/s]                               \n100%|█████████▉| 399999/400000 [00:26<00:00, 14873.65it/s]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "embedding_matrix = torch.zeros(len(vocab), glove_vectors.dim)\nfor i, token in enumerate(vocab.get_itos()):\n    embedding_matrix[i] = glove_vectors[token]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:42:48.811656Z",
     "iopub.execute_input": "2024-11-01T18:42:48.812333Z",
     "iopub.status.idle": "2024-11-01T18:42:49.043154Z",
     "shell.execute_reply.started": "2024-11-01T18:42:48.812283Z",
     "shell.execute_reply": "2024-11-01T18:42:49.042462Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text))\n",
    "        text_list.append(processed_text)\n",
    "    return (\n",
    "        torch.tensor(label_list, dtype=torch.float64).to(device),\n",
    "        pad_sequence(text_list, padding_value=1.0).to(device),\n",
    "    )\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def batch_sampler():\n",
    "    indices = [(i, len(tokenizer(s[1]))) for i, s in enumerate(train_data)]\n",
    "    random.shuffle(indices)\n",
    "    pooled_indices = []\n",
    "\n",
    "    for i in range(0, len(indices), batch_size * CODING_SZ):\n",
    "        pooled_indices.extend(\n",
    "            sorted(indices[i : i + batch_size * CODING_SZ], key=lambda x: x[1])\n",
    "        )\n",
    "        pooled_indices = [x[0] for x in pooled_indices]\n",
    "\n",
    "        for i in range(0, len(pooled_indices), batch_size):\n",
    "            yield pooled_indices[i : i + batch_size]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:42:49.044370Z",
     "iopub.execute_input": "2024-11-01T18:42:49.044980Z",
     "iopub.status.idle": "2024-11-01T18:42:49.062251Z",
     "shell.execute_reply.started": "2024-11-01T18:42:49.044935Z",
     "shell.execute_reply": "2024-11-01T18:42:49.061349Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "CODING_SZ = 100\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    #                            batch_sampler=batch_sampler(),\n",
    "    collate_fn=collate_batch,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data, collate_fn=collate_batch, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, collate_fn=collate_batch, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:42:49.063591Z",
     "iopub.execute_input": "2024-11-01T18:42:49.064055Z",
     "iopub.status.idle": "2024-11-01T18:42:49.079848Z",
     "shell.execute_reply.started": "2024-11-01T18:42:49.064012Z",
     "shell.execute_reply": "2024-11-01T18:42:49.078950Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.embedding.weight.data.copy_(embedding_matrix)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text).permute(1, 0, 2)\n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1)\n",
    "        return self.fc(pooled)\n",
    "\n",
    "\n",
    "model = FastText(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=CODING_SZ,\n",
    "    output_dim=1,\n",
    "    pad_idx=vocab[PAD_TOKEN],\n",
    ")\n",
    "model.embedding.weight.data[vocab[UNK_TOKEN]] = torch.zeros(CODING_SZ)\n",
    "model.embedding.weight.data[vocab[UNK_TOKEN]] = torch.zeros(CODING_SZ)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:42:49.081068Z",
     "iopub.execute_input": "2024-11-01T18:42:49.081550Z",
     "iopub.status.idle": "2024-11-01T18:42:49.110890Z",
     "shell.execute_reply.started": "2024-11-01T18:42:49.081468Z",
     "shell.execute_reply": "2024-11-01T18:42:49.110041Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:42:49.113855Z",
     "iopub.execute_input": "2024-11-01T18:42:49.114242Z",
     "iopub.status.idle": "2024-11-01T18:42:49.929548Z",
     "shell.execute_reply.started": "2024-11-01T18:42:49.114210Z",
     "shell.execute_reply": "2024-11-01T18:42:49.928770Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCHS = 3\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for label, text in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text).squeeze(1)\n",
    "        loss = criterion(predictions, label)\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == label).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(\n",
    "        \"Epoch %d Train: Loss: %.4f Acc: %.4f\"\n",
    "        % (epoch, epoch_loss / len(train_dataloader), epoch_acc / len(train_dataloader))\n",
    "    )\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for label, text in tqdm(valid_dataloader, total=len(valid_dataloader)):\n",
    "            predictions = model(text).squeeze(1)\n",
    "            loss = criterion(predictions, label)\n",
    "\n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            correct = (rounded_preds == label).float()\n",
    "            acc = correct.sum() / len(correct)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    print(\n",
    "        \"Epoch %d Valid: Loss: %.4f Acc: %.4f\"\n",
    "        % (epoch, epoch_loss / len(valid_dataloader), epoch_acc / len(valid_dataloader))\n",
    "    )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:42:49.930816Z",
     "iopub.execute_input": "2024-11-01T18:42:49.931343Z",
     "iopub.status.idle": "2024-11-01T18:45:05.554196Z",
     "shell.execute_reply.started": "2024-11-01T18:42:49.931308Z",
     "shell.execute_reply": "2024-11-01T18:45:05.553276Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "text": "100%|██████████| 274/274 [00:32<00:00,  8.49it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 0 Train: Loss: 0.4072 Acc: 0.9378\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 118/118 [00:14<00:00,  8.07it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 0 Valid: Loss: 0.1661 Acc: 1.0000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 274/274 [00:31<00:00,  8.68it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1 Train: Loss: 0.0926 Acc: 1.0000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 118/118 [00:12<00:00,  9.23it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1 Valid: Loss: 0.0535 Acc: 1.0000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 274/274 [00:31<00:00,  8.66it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 2 Train: Loss: 0.0360 Acc: 1.0000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 118/118 [00:12<00:00,  9.28it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 2 Valid: Loss: 0.0261 Acc: 1.0000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_loss = 0\n",
    "test_acc = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for label, text in tqdm(test_dataloader):\n",
    "        predictions = model(text).squeeze(1)\n",
    "        loss = criterion(predictions, label)\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == label).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_acc += acc.item()\n",
    "\n",
    "print(\n",
    "    \"Test: Loss: %.4f Acc: %.4f\"\n",
    "    % (test_loss / len(test_dataloader), test_acc / len(test_dataloader))\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:45:05.555295Z",
     "iopub.execute_input": "2024-11-01T18:45:05.555593Z",
     "iopub.status.idle": "2024-11-01T18:45:51.904651Z",
     "shell.execute_reply.started": "2024-11-01T18:45:05.555561Z",
     "shell.execute_reply": "2024-11-01T18:45:51.903699Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "text": "100%|██████████| 391/391 [00:46<00:00,  8.44it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Test: Loss: 0.0247 Acc: 1.0000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "criterion(predictions, label)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:45:51.905758Z",
     "iopub.execute_input": "2024-11-01T18:45:51.906099Z",
     "iopub.status.idle": "2024-11-01T18:45:51.966351Z",
     "shell.execute_reply.started": "2024-11-01T18:45:51.906065Z",
     "shell.execute_reply": "2024-11-01T18:45:51.965454Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(0.0344, device='cuda:0', dtype=torch.float64)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "rounded_preds",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:45:51.967609Z",
     "iopub.execute_input": "2024-11-01T18:45:51.968368Z",
     "iopub.status.idle": "2024-11-01T18:45:51.974877Z",
     "shell.execute_reply.started": "2024-11-01T18:45:51.968321Z",
     "shell.execute_reply": "2024-11-01T18:45:51.973895Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "execution_count": 14,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       device='cuda:0')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "label",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:45:51.975963Z",
     "iopub.execute_input": "2024-11-01T18:45:51.976226Z",
     "iopub.status.idle": "2024-11-01T18:45:51.988494Z",
     "shell.execute_reply.started": "2024-11-01T18:45:51.976197Z",
     "shell.execute_reply": "2024-11-01T18:45:51.987648Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "execution_count": 15,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       device='cuda:0', dtype=torch.float64)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "(text).shape",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-01T18:45:51.989437Z",
     "iopub.execute_input": "2024-11-01T18:45:51.989728Z",
     "iopub.status.idle": "2024-11-01T18:45:51.997628Z",
     "shell.execute_reply.started": "2024-11-01T18:45:51.989697Z",
     "shell.execute_reply": "2024-11-01T18:45:51.996875Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "execution_count": 16,
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([2331, 40])"
     },
     "metadata": {}
    }
   ]
  }
 ]
}